{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intent Detection\n",
        "> **Text Classification Problem** to `identify the Glorious Purpose` of `user's utterance.` It is very crucial for **Text-Based** applications like Chatbots where both the Inputs and Outputs are in the form of texts."
      ],
      "metadata": {
        "id": "11FZSdvF9E5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Points\n",
        "\n",
        "* **Knowledge distillation** is a technique that **transfers knowledge** from `Larger Complex Model to Smaller Simple Model`.\n",
        "\n",
        "* **Quantization** is a technique that **reduces precision** of `model weights and activation functions` to **speed up inference** and **save memory**.\n",
        "\n",
        "* **Pruning** is a technique that **removes redundant model parameters** to `reduce model size and model complexity`."
      ],
      "metadata": {
        "id": "rdpEdFKnFdv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario"
      ],
      "metadata": {
        "id": "X2Vc3BcTFNh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say I am making **Jarvis** to help me with Stock Market. So when I ask Jarvis \"`Hey, I have done some savings, I want to invest some of it in the Stock Market for stable monthly income of 6%...`\", then Jarvis should be able to auto categorize it as \"`Investing`\" intent. And when I ask Jarvis something out of the scope like \"`Find me a date...`\", then Jarvis should say \"`üëéüèª You are not eligible. Focus on your Finance instead, that's more future-proof...`\"."
      ],
      "metadata": {
        "id": "jkK98hoHFcxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "> **CLINC150** A dataset for **intent detection** with 150 intents in 10 domains and out-of-scope examples."
      ],
      "metadata": {
        "id": "2U9h2YW3LnuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Purpose**: To test intent detection models on realistic and challenging queries that may not fit any intent.\n",
        "\n",
        "**Size**: The dataset has **23,700** examples in total, with **22,500 in-scope examples** and **1,200 out-of-scope examples**.\n",
        "\n",
        "* The **in-scope examples** are divided into 100 train, 20 validation, and 30 test sets examples per intent class.\n",
        "    \n",
        "* The **out-of-scope examples** are divided into 100 train, 100 validation, and 1,000 test examples.\n",
        "\n",
        "**Variants**: The dataset has four variants:\n",
        "\n",
        "* **data_full** variant is the main version of the dataset, with 100 train examples per in-scope class.\n",
        "\n",
        "* **data_small** variant has 50 train examples per in-scope class.\n",
        "\n",
        "* **data_imbalanced** variant has either 25, 50, 75, or 100 train examples per in-scope class, randomly assigned.\n",
        "\n",
        "* **data_oos_plus** variant is the same as data_full, except it has 250 out-of-scope train examples.\n",
        "\n",
        "**Benchmarks**: The dataset has been used to benchmark various intent classification models, such as **BERT, RoBERTa**, and **DSSCC**. The models are evaluated on their `accuracy` and `F1-score` on the in-scope and out-of-scope test sets.\n",
        "\n",
        "* The **current state-of-the-art model** is `RoBERTa-Large + ICDA`, which achieves **98.9% accuracy** and **98.8% F1-score** on the in-scope test set, and **95.7% accuracy** and **95.6% F1-score** on the out-of-scope test set.\n",
        "\n",
        "**Source**: A paper by Larson et al [‚ÄúAn Evaluation Dataset for Intent Classification and Out-of-Scope Prediction‚Äù](https://archive.ics.uci.edu/dataset/570/clinc150)."
      ],
      "metadata": {
        "id": "ksrLXXySLqfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Started"
      ],
      "metadata": {
        "id": "WRACvyWiUadK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "aogPzWQwFNHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRG9-2sY8-KW"
      },
      "outputs": [],
      "source": [
        "model_checkpoint=\"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "pipe=pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=model_checkpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in\n",
        "Paris and I need a 15 passenger van\"\"\"\n",
        "pipe(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHMLE6rTW_MB",
        "outputId": "eec25f95-6be6-4bdc-f7ef-95f1f8fbd91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'car_rental', 'score': 0.5490031242370605}]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I have done some savings, I want to invest some of it in\n",
        "the Stock Market for stable monthly income of 6%...\"\"\"\n",
        "pipe(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilQkCfwMXspr",
        "outputId": "f0682cb7-3aa2-4d03-ebd3-e567bbf529f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'direct_deposit', 'score': 0.1069217249751091}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Find me a date...\"\"\"\n",
        "pipe(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxA5E-5AX6Il",
        "outputId": "ea75d032-3188-407f-8e8a-6848fe00ca84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'date', 'score': 0.5273397564888}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Performance Benchmark"
      ],
      "metadata": {
        "id": "hT5wD2MCYm_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model performance\n",
        "\n",
        "How well does our model perform on a well-crafted test set that reflects production data? This is especially important when the cost of making errors is large (and best mitigated with a human in the loop), or when we need to run inference on millions of examples and small improvements to the model metrics can translate into large gains in aggregate.\n",
        "\n",
        "### Latency\n",
        "\n",
        "How fast can our model deliver predictions? We usually care about latency in real-time environments that deal with a lot of traffic, like how Stack Overflow needed a classifier to quickly detect unwelcome comments on the website.\n",
        "\n",
        "### Memory\n",
        "\n",
        "How can we deploy billion-parameter models like GPT-2 or T5 that require giga-bytes of disk storage and RAM? Memory plays an especially important role in mobile or edge devices, where a model has to generate predictions without access to a powerful cloud server."
      ],
      "metadata": {
        "id": "aFJYq8bLY7tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text explains the importance of evaluating the model performance on a test set that is similar to the real-world data that the model will encounter in production. The text also mentions some scenarios where the model performance can have a significant impact on the outcome, such as when the model errors are costly or when the model is applied to a large scale of data. The text implies that the model performance should be measured by appropriate metrics that reflect the desired objectives and trade-offs.\n",
        "\n",
        "* **Model performance**: How well the model can predict the correct labels for the input data.\n",
        "\n",
        "* **Test set**: A subset of data that is used to evaluate the model performance after training. The test set should reflect the production data as much as possible.\n",
        "\n",
        "* **Cost of errors**: The potential negative consequences of the model making wrong predictions, such as losing customers, money, or reputation. Errors can be reduced by involving a human expert to check or correct the model outputs.\n",
        "\n",
        "* **Scale of inference**: The amount of data that the model needs to process and make predictions for. A large scale of inference can amplify the benefits or drawbacks of the model performance."
      ],
      "metadata": {
        "id": "WOJ1iN-bdGHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Benchmark\n",
        ">  Use the `test set` to benchmark models."
      ],
      "metadata": {
        "id": "F_YI2ebmMcYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerformanceBenchmark:\n",
        "    def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\"):\n",
        "        self.pipeline=pipeline\n",
        "        self.dataset=dataset\n",
        "        self.optim_type=optim_type # keep track of different optimization techniques\n",
        "\n",
        "    def computeAccuracy(self):\n",
        "        pass\n",
        "\n",
        "    def computeSize(self):\n",
        "        pass\n",
        "\n",
        "    def timePipeline(self):\n",
        "        pass\n",
        "\n",
        "    def runBenchmark(self):\n",
        "        metrics:dict[str,set|dict] = dict() # collect all the metrics in dictionary, with keys given by optim_type\n",
        "        metrics[self.optim_type]=self.computeSize()\n",
        "        metrics[self.optim_type].update(self.timePipeline())\n",
        "        metrics[self.optim_type].update(self.computeAccuracy())\n",
        "        return metrics"
      ],
      "metadata": {
        "id": "ySgpOnjjYCHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets -Uqq"
      ],
      "metadata": {
        "id": "JguXjkqMN2Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data=load_dataset(\n",
        "    path=\"clinc_oos\",\n",
        "    name=\"plus\", # refers to the subset containing out-of-scope training examples\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "id": "HyflLFcdN7lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDK0xFF2QShQ",
        "outputId": "d621d865-4798-4d19-b03f-5b17cbe26956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 15250\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 3100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 5500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"test\"].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwucWLrkh6Ab",
        "outputId": "a174e4a3-83b5-4160-8f2c-30b80f991a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'intent': ClassLabel(names=['restaurant_reviews', 'nutrition_info', 'account_blocked', 'oil_change_how', 'time', 'weather', 'redeem_rewards', 'interest_rate', 'gas_type', 'accept_reservations', 'smart_home', 'user_name', 'report_lost_card', 'repeat', 'whisper_mode', 'what_are_your_hobbies', 'order', 'jump_start', 'schedule_meeting', 'meeting_schedule', 'freeze_account', 'what_song', 'meaning_of_life', 'restaurant_reservation', 'traffic', 'make_call', 'text', 'bill_balance', 'improve_credit_score', 'change_language', 'no', 'measurement_conversion', 'timer', 'flip_coin', 'do_you_have_pets', 'balance', 'tell_joke', 'last_maintenance', 'exchange_rate', 'uber', 'car_rental', 'credit_limit', 'oos', 'shopping_list', 'expiration_date', 'routing', 'meal_suggestion', 'tire_change', 'todo_list', 'card_declined', 'rewards_balance', 'change_accent', 'vaccines', 'reminder_update', 'food_last', 'change_ai_name', 'bill_due', 'who_do_you_work_for', 'share_location', 'international_visa', 'calendar', 'translate', 'carry_on', 'book_flight', 'insurance_change', 'todo_list_update', 'timezone', 'cancel_reservation', 'transactions', 'credit_score', 'report_fraud', 'spending_history', 'directions', 'spelling', 'insurance', 'what_is_your_name', 'reminder', 'where_are_you_from', 'distance', 'payday', 'flight_status', 'find_phone', 'greeting', 'alarm', 'order_status', 'confirm_reservation', 'cook_time', 'damaged_card', 'reset_settings', 'pin_change', 'replacement_card_duration', 'new_card', 'roll_dice', 'income', 'taxes', 'date', 'who_made_you', 'pto_request', 'tire_pressure', 'how_old_are_you', 'rollover_401k', 'pto_request_status', 'how_busy', 'application_status', 'recipe', 'calendar_update', 'play_music', 'yes', 'direct_deposit', 'credit_limit_change', 'gas', 'pay_bill', 'ingredients_list', 'lost_luggage', 'goodbye', 'what_can_i_ask_you', 'book_hotel', 'are_you_a_bot', 'next_song', 'change_speed', 'plug_type', 'maybe', 'w2', 'oil_change_when', 'thank_you', 'shopping_list_update', 'pto_balance', 'order_checks', 'travel_alert', 'fun_fact', 'sync_device', 'schedule_maintenance', 'apr', 'transfer', 'ingredient_substitution', 'calories', 'current_location', 'international_fees', 'calculator', 'definition', 'next_holiday', 'update_playlist', 'mpg', 'min_payment', 'change_user_name', 'restaurant_suggestion', 'travel_notification', 'cancel', 'pto_used', 'travel_suggestion', 'change_volume'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"test\"].to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ql7pJoIQg7cp",
        "outputId": "9533e308-68a4-40a6-a3c8-ce71b62d3f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            text  intent\n",
              "0               how would you say fly in italian      61\n",
              "1              what's the spanish word for pasta      61\n",
              "2            how would they say butter in zambia      61\n",
              "3                 how do you say fast in spanish      61\n",
              "4            what's the word for trees in norway      61\n",
              "...                                          ...     ...\n",
              "5495                              find my wallet      42\n",
              "5496  can you give me the gps location of harvey      42\n",
              "5497    where's my buddy steve right this second      42\n",
              "5498        locate jenny at her present position      42\n",
              "5499          let me know where jim is right now      42\n",
              "\n",
              "[5500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1732f28-2eb7-4a23-8413-7c79127b7013\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how would you say fly in italian</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what's the spanish word for pasta</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how would they say butter in zambia</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how do you say fast in spanish</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what's the word for trees in norway</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5495</th>\n",
              "      <td>find my wallet</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5496</th>\n",
              "      <td>can you give me the gps location of harvey</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5497</th>\n",
              "      <td>where's my buddy steve right this second</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5498</th>\n",
              "      <td>locate jenny at her present position</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5499</th>\n",
              "      <td>let me know where jim is right now</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5500 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1732f28-2eb7-4a23-8413-7c79127b7013')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1732f28-2eb7-4a23-8413-7c79127b7013 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1732f28-2eb7-4a23-8413-7c79127b7013');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-431609c7-2fb0-4e35-bec3-574c3e42c815\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-431609c7-2fb0-4e35-bec3-574c3e42c815')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-431609c7-2fb0-4e35-bec3-574c3e42c815 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"test\"].features[\"intent\"].int2str(values=[61,42])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHC_UWufhRmX",
        "outputId": "d8540c2d-5ec3-453e-d655-114784d556d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['translate', 'oos']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"test\"].features[\"intent\"].int2str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amMItfDWh0xp",
        "outputId": "3ff9faee-d748-4c27-ff6c-66292b680d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ClassLabel.int2str of ClassLabel(names=['restaurant_reviews', 'nutrition_info', 'account_blocked', 'oil_change_how', 'time', 'weather', 'redeem_rewards', 'interest_rate', 'gas_type', 'accept_reservations', 'smart_home', 'user_name', 'report_lost_card', 'repeat', 'whisper_mode', 'what_are_your_hobbies', 'order', 'jump_start', 'schedule_meeting', 'meeting_schedule', 'freeze_account', 'what_song', 'meaning_of_life', 'restaurant_reservation', 'traffic', 'make_call', 'text', 'bill_balance', 'improve_credit_score', 'change_language', 'no', 'measurement_conversion', 'timer', 'flip_coin', 'do_you_have_pets', 'balance', 'tell_joke', 'last_maintenance', 'exchange_rate', 'uber', 'car_rental', 'credit_limit', 'oos', 'shopping_list', 'expiration_date', 'routing', 'meal_suggestion', 'tire_change', 'todo_list', 'card_declined', 'rewards_balance', 'change_accent', 'vaccines', 'reminder_update', 'food_last', 'change_ai_name', 'bill_due', 'who_do_you_work_for', 'share_location', 'international_visa', 'calendar', 'translate', 'carry_on', 'book_flight', 'insurance_change', 'todo_list_update', 'timezone', 'cancel_reservation', 'transactions', 'credit_score', 'report_fraud', 'spending_history', 'directions', 'spelling', 'insurance', 'what_is_your_name', 'reminder', 'where_are_you_from', 'distance', 'payday', 'flight_status', 'find_phone', 'greeting', 'alarm', 'order_status', 'confirm_reservation', 'cook_time', 'damaged_card', 'reset_settings', 'pin_change', 'replacement_card_duration', 'new_card', 'roll_dice', 'income', 'taxes', 'date', 'who_made_you', 'pto_request', 'tire_pressure', 'how_old_are_you', 'rollover_401k', 'pto_request_status', 'how_busy', 'application_status', 'recipe', 'calendar_update', 'play_music', 'yes', 'direct_deposit', 'credit_limit_change', 'gas', 'pay_bill', 'ingredients_list', 'lost_luggage', 'goodbye', 'what_can_i_ask_you', 'book_hotel', 'are_you_a_bot', 'next_song', 'change_speed', 'plug_type', 'maybe', 'w2', 'oil_change_when', 'thank_you', 'shopping_list_update', 'pto_balance', 'order_checks', 'travel_alert', 'fun_fact', 'sync_device', 'schedule_maintenance', 'apr', 'transfer', 'ingredient_substitution', 'calories', 'current_location', 'international_fees', 'calculator', 'definition', 'next_holiday', 'update_playlist', 'mpg', 'min_payment', 'change_user_name', 'restaurant_suggestion', 'travel_notification', 'cancel', 'pto_used', 'travel_suggestion', 'change_volume'], id=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## computeAccuracy\n",
        "> Accuracy is **effective** when the target feature's classes are `balanced`."
      ],
      "metadata": {
        "id": "sfV6jmCei4qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install evaluate -Uqq"
      ],
      "metadata": {
        "id": "ava97qqYilc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "accuracy_score=load(path=\"accuracy\")"
      ],
      "metadata": {
        "id": "OQn6nL08kNCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# expects y_true(references), y_pred(predictions)\n",
        "accuracy_score.compute(references=[5,3,7], predictions=[5,3,6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2Dad3wbkSp9",
        "outputId": "be7935c0-c33f-4340-af34-7c8efe3e01c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample=data[\"test\"][0][\"text\"]\n",
        "prediction=pipe(sample)\n",
        "prediction_label=prediction[0][\"label\"]\n",
        "prediction_id=data[\"test\"].features[\"intent\"].str2int(prediction_label)\n",
        "\n",
        "print(sample)\n",
        "print(prediction)\n",
        "print(prediction_label,\"--->\", prediction_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D03xuY2WkdTl",
        "outputId": "57297de3-b6cb-4f28-df3d-0c762307bc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how would you say fly in italian\n",
            "[{'label': 'translate', 'score': 0.5855257511138916}]\n",
            "translate ---> 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example in data[\"test\"]:\n",
        "    print(example)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUVltrxJoVvI",
        "outputId": "b18e5b88-f6c5-4b07-bb0f-ee0aade84a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'how would you say fly in italian', 'intent': 61}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def computeAccuracy(self):\n",
        "    \"\"\"Override the PerformanceBenchmark.computeAccuracy() method\"\"\"\n",
        "    prediction_ids:[int]=[]\n",
        "    labels:[str]=[]\n",
        "    intents=self.dataset[\"test\"].features[\"intent\"]\n",
        "\n",
        "    for example in self.dataset[\"test\"]:\n",
        "        pred_label=self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "        pred_id=intents.str2int(pred_label)\n",
        "        prediction_ids.append(pred_id)\n",
        "\n",
        "        label=example[\"intent\"]\n",
        "        labels.append(label)\n",
        "    accuracy=accuracy_score.compute(references=labels, predictions=prediction_ids)\n",
        "    print(f\"Accuracy on test set ---> {accuracy['accuracy']:.4f}\")\n",
        "    return accuracy\n",
        "\n",
        "# Override the PerformanceBenchmark.computeAccuracy() method\n",
        "PerformanceBenchmark.computeAccuracy=computeAccuracy"
      ],
      "metadata": {
        "id": "XKALGOitlQmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(pipe.model.state_dict().items())[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm7j4f7Mtqb9",
        "outputId": "24dc569d-4bcd-4ee8-fd8d-5c71a4836a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert.encoder.layer.2.attention.self.value.bias',\n",
              " tensor([-2.7834e-02,  4.9434e-02,  8.3551e-02,  4.1092e-02,  6.0157e-01,\n",
              "          1.1774e-01, -5.2112e-02, -6.5143e-02, -2.9358e-02, -4.2250e-02,\n",
              "          7.9177e-02,  8.0409e-02,  2.9921e-03,  1.7816e-01, -5.0480e-02,\n",
              "         -1.5634e-01, -2.1707e-02,  1.4381e-02,  2.5132e-02, -2.4110e-02,\n",
              "         -1.9183e-01, -7.8657e-02,  5.0709e-02,  3.3632e-02, -3.1946e-02,\n",
              "          1.1616e-01,  9.2720e-02, -1.1787e-01,  2.3233e-01, -1.2678e-02,\n",
              "         -1.3138e-01, -4.0024e-02,  7.4823e-02, -5.4148e-02, -1.5184e-01,\n",
              "         -7.4407e-02,  1.1559e-01,  8.2729e-02, -1.3787e-01,  8.3528e-02,\n",
              "          1.2154e-01,  1.6880e-02, -5.6629e-02, -3.9295e-02,  5.3725e-02,\n",
              "          6.8602e-02, -1.1294e-01,  4.4001e-02, -2.5884e-01,  1.6767e-01,\n",
              "          1.8316e-01,  5.6272e-02, -3.6874e-02, -2.7938e-02, -9.3204e-02,\n",
              "         -7.5239e-03,  4.1141e-02, -1.1542e-02, -9.9749e-02, -3.0910e-02,\n",
              "          4.1398e-02, -4.4389e-02, -2.6279e-02,  7.2100e-02,  7.5179e-03,\n",
              "         -7.4382e-03,  2.9311e-02, -1.3391e-02,  6.9966e-03, -9.3249e-03,\n",
              "          9.4272e-03, -1.1783e-02,  1.3849e-02,  1.8157e-03, -1.1522e-02,\n",
              "          1.3364e-02, -2.6307e-02,  2.3725e-03, -4.8451e-03,  6.2261e-03,\n",
              "          1.2653e-02,  1.7601e-02, -1.7971e-02, -2.9247e-03, -3.3447e-03,\n",
              "          1.4263e-02, -3.5629e-03, -9.2794e-03, -2.1326e-02,  1.9390e-02,\n",
              "          1.3287e-02, -8.7034e-03,  1.2936e-02, -2.0574e-02,  3.2204e-03,\n",
              "          5.9970e-03, -5.6524e-02,  3.0851e-02, -2.3233e-02,  4.6271e-02,\n",
              "         -1.4485e-03,  4.4248e-04, -3.1102e-02,  1.9762e-02,  2.0866e-02,\n",
              "          1.7914e-02, -2.0622e-02, -1.6030e-02,  6.2167e-03,  1.6809e-02,\n",
              "          4.6357e-03,  4.7169e-02, -2.1151e-02, -1.8898e-02,  3.5921e-02,\n",
              "          4.8621e-03, -5.9841e-02, -1.3029e-02,  5.6702e-03,  1.6820e-02,\n",
              "          2.1735e-02, -2.8285e-03, -1.5519e-02,  7.1974e-03,  3.5492e-02,\n",
              "         -2.3190e-02, -9.7930e-03,  2.3223e-02,  2.0529e-02,  2.7412e-02,\n",
              "          1.3887e-02,  1.7976e-03, -3.8905e-02,  1.8540e-02,  8.0013e-03,\n",
              "         -8.3682e-03, -8.6805e-03,  2.6464e-02,  1.8968e-03, -1.8028e-03,\n",
              "         -2.4427e-02, -3.5514e-02, -1.8748e-02, -3.0541e-02, -7.9520e-03,\n",
              "         -1.5989e-02,  9.3060e-03,  2.9318e-02,  1.6679e-02, -2.4060e-03,\n",
              "         -7.2656e-03, -2.7699e-03,  1.4280e-02, -6.7352e-02, -1.2329e-02,\n",
              "         -1.1516e-02, -8.0379e-03,  2.5604e-02, -2.9178e-02,  2.6076e-02,\n",
              "         -1.1561e-02, -4.0904e-03, -1.7735e-02, -2.8245e-03,  2.3919e-02,\n",
              "         -3.6326e-03, -1.6407e-03,  9.5295e-03,  2.4161e-02, -5.8965e-02,\n",
              "          4.7633e-02,  1.4403e-03, -4.4763e-02, -3.5462e-03,  3.0613e-02,\n",
              "          2.5047e-02,  1.3757e-02, -2.2238e-02,  8.0453e-03, -2.6188e-03,\n",
              "         -2.2013e-03, -6.0179e-03, -8.5149e-03, -2.8150e-02,  1.9282e-02,\n",
              "         -7.5657e-02,  6.1354e-03,  5.2562e-03, -2.2223e-03,  1.0437e-02,\n",
              "         -1.8630e-02, -7.7628e-02,  1.4377e-02,  1.4977e-02,  1.6090e-02,\n",
              "          2.9399e-02, -2.8604e-02, -3.2916e-02,  2.7902e-03,  1.4113e-02,\n",
              "          8.3836e-03, -6.5914e-03, -4.9576e-03, -1.5955e-02,  4.2381e-03,\n",
              "          3.0032e-02,  8.8986e-03, -1.5336e-02,  4.6771e-03, -1.2364e-02,\n",
              "         -3.7724e-02, -3.9060e-03,  1.4607e-02, -2.1286e-02,  9.7086e-03,\n",
              "         -1.5826e-02, -1.4847e-02,  1.0796e-03, -9.5035e-03, -1.8624e-02,\n",
              "         -3.1673e-02,  8.8388e-03, -1.4921e-02, -1.7855e-03,  3.8781e-02,\n",
              "          2.4269e-02, -1.6465e-03, -7.9774e-03, -1.3907e-02,  1.9653e-03,\n",
              "         -2.6717e-03,  3.0146e-02, -4.3986e-03,  6.0588e-03,  2.1959e-02,\n",
              "          2.0354e-02,  9.3631e-03, -8.4828e-03, -2.3994e-02,  1.8316e-02,\n",
              "         -2.2401e-02, -2.6273e-03,  3.2069e-03, -3.2386e-03,  1.1388e-02,\n",
              "          3.0835e-02,  2.6043e-02, -7.2103e-03, -5.0038e-04, -1.4860e-02,\n",
              "          2.3886e-02,  1.1530e-02, -1.0549e-03,  3.5677e-02,  6.0299e-03,\n",
              "          1.5875e-02,  5.3877e-02,  6.6331e-02,  1.5165e-02, -6.0870e-03,\n",
              "          1.6159e-03, -1.1137e-02,  1.3665e-02,  1.7698e-02,  4.5647e-03,\n",
              "         -4.5349e-02,  2.6634e-02,  4.7289e-03, -1.1664e-02,  8.7302e-03,\n",
              "          1.2051e-02,  2.3455e-02, -2.7151e-03, -1.3474e-02, -4.5949e-02,\n",
              "         -1.3496e-02,  8.1680e-02, -2.9737e-02, -2.8525e-02, -1.4888e-02,\n",
              "          5.4320e-03,  3.9142e-02,  1.4227e-02,  1.1140e-02, -1.0980e-02,\n",
              "          2.1982e-02, -1.1148e-02, -1.0226e-02, -5.8499e-03, -1.9739e-02,\n",
              "         -3.4634e-03, -1.0565e-02,  1.0449e-02,  8.2791e-03,  2.3053e-03,\n",
              "          9.7032e-03, -9.0916e-03,  5.4747e-04, -4.1901e-02,  9.6154e-03,\n",
              "          2.9424e-02,  1.1897e-03,  1.1825e-02,  2.7524e-02,  1.0225e-02,\n",
              "          2.1439e-02,  2.3448e-03, -3.7239e-02,  5.8888e-02, -3.1999e-02,\n",
              "         -7.9128e-03,  3.5337e-02,  2.7251e-02,  1.3948e-02,  1.0896e-02,\n",
              "          1.4326e-05, -2.6835e-03,  4.0720e-03,  1.6469e-02,  3.5876e-02,\n",
              "         -1.6803e-02,  2.8083e-02,  2.2789e-03,  3.1635e-02,  5.7104e-03,\n",
              "          3.0284e-03,  1.2528e-02, -1.7956e-02, -1.4686e-02,  4.4091e-03,\n",
              "         -1.4846e-02, -4.1044e-02, -3.4005e-02, -6.5876e-02,  3.0926e-02,\n",
              "          5.9820e-02, -1.0069e-04, -6.6089e-03,  2.1271e-03,  3.6137e-03,\n",
              "          9.0073e-03,  9.6992e-03,  2.1992e-02,  6.2104e-02,  1.4786e-02,\n",
              "         -2.6120e-02, -1.4990e-02,  1.5148e-02,  3.0313e-02,  2.0834e-02,\n",
              "          1.7836e-02, -5.4321e-03, -5.9164e-03,  1.7840e-02, -4.3020e-03,\n",
              "          8.7374e-03, -2.4993e-02,  3.4310e-02,  2.2652e-02, -5.3760e-03,\n",
              "          1.7668e-02, -8.9518e-04,  1.3691e-03, -2.1373e-02, -6.1878e-03,\n",
              "         -1.2396e-02, -1.7816e-02, -1.8014e-02,  9.5274e-03,  1.1643e-02,\n",
              "         -2.0683e-02, -2.8707e-03,  1.1669e-02,  1.5618e-02,  3.5348e-02,\n",
              "         -1.1234e-02, -4.5453e-03, -3.4890e-02, -3.0010e-02,  1.6433e-02,\n",
              "         -1.2068e-02,  8.2583e-03,  1.4090e-02,  1.8771e-02, -4.9337e-02,\n",
              "         -1.7775e-03,  5.6333e-02,  6.8979e-02,  2.3123e-02, -1.0754e-02,\n",
              "         -4.9530e-02,  4.2980e-02,  2.8846e-02, -3.9176e-02,  8.1903e-02,\n",
              "         -2.9344e-02,  3.0343e-02,  8.4269e-02, -2.4376e-02, -8.4680e-02,\n",
              "          6.7452e-03,  1.2407e-01,  1.5680e-02, -1.6643e-02,  9.0987e-03,\n",
              "         -2.7984e-03,  7.5874e-02, -1.4630e-02,  2.9823e-02, -1.0423e-02,\n",
              "         -6.0341e-02, -3.6580e-02, -5.4615e-02, -1.3628e-01, -5.8373e-02,\n",
              "          4.3453e-02,  3.0439e-02,  1.7298e-02, -1.1724e-01,  1.0805e-01,\n",
              "         -4.6345e-02, -1.1533e-01,  7.4684e-02, -5.9752e-03,  4.3189e-02,\n",
              "          4.4795e-02, -3.7566e-03, -7.5097e-02,  3.5959e-02,  1.3906e-01,\n",
              "          4.6041e-02,  1.1786e-02,  1.1243e-01,  8.4072e-02, -7.7309e-02,\n",
              "          1.3586e-02,  9.5244e-02, -1.2002e-01,  7.0882e-02,  1.0043e-01,\n",
              "          2.5874e-02,  2.3354e-02, -3.5469e-02,  3.0738e-02,  1.0479e-01,\n",
              "         -9.2843e-02,  5.9718e-02, -1.9409e-02, -3.4414e-02, -8.4060e-03,\n",
              "         -9.3654e-03, -2.8030e-02,  7.2026e-03, -5.9461e-03, -1.2284e-02,\n",
              "         -1.7473e-02, -4.9678e-02,  1.0224e-02, -1.4688e-02, -1.7345e-02,\n",
              "          2.6771e-02, -2.6582e-02, -2.9768e-02,  6.2005e-03, -3.3405e-04,\n",
              "          9.1245e-03, -3.7149e-02, -6.7714e-03, -1.8193e-02,  3.4191e-02,\n",
              "         -5.5732e-03, -2.6161e-02, -1.4078e-02,  1.0288e-02, -2.2850e-02,\n",
              "         -2.2642e-02,  1.0270e-02,  6.9930e-03,  1.3614e-03, -2.9319e-04,\n",
              "          9.9593e-03, -6.0532e-03,  1.8669e-03, -5.3395e-03, -2.2013e-02,\n",
              "          8.4485e-03, -1.9142e-02,  1.0449e-02, -1.6700e-02,  1.3038e-02,\n",
              "          7.7479e-03, -1.3329e-02,  1.3052e-02, -2.5305e-03,  1.6191e-02,\n",
              "          1.3152e-02,  2.9897e-02,  8.5553e-03, -6.4898e-04,  1.2359e-02,\n",
              "         -4.2144e-03,  2.1785e-02,  2.1401e-02, -1.3295e-02,  7.4764e-03,\n",
              "          6.3580e-03, -6.2467e-03,  1.8235e-02,  3.0643e-02, -4.9091e-03,\n",
              "         -1.3889e-02,  2.6181e-03,  4.9702e-03, -6.1664e-03, -2.8528e-03,\n",
              "         -4.0556e-04,  5.4844e-03,  9.7783e-03,  1.2326e-02, -1.6844e-02,\n",
              "         -1.6294e-02,  4.9879e-03,  3.7789e-03,  8.0305e-04,  2.0482e-02,\n",
              "         -1.6369e-02,  1.6436e-03, -9.0401e-03, -3.2635e-02, -2.3990e-03,\n",
              "          5.7569e-03, -2.0392e-02,  6.6946e-03, -1.8541e-02,  9.3559e-03,\n",
              "          2.7165e-02,  1.2492e-02,  1.2748e-03, -1.3846e-03,  4.0312e-03,\n",
              "         -8.5552e-03,  3.1621e-03, -3.9514e-02, -3.7938e-03, -1.3551e-02,\n",
              "          2.2692e-02, -1.0217e-02, -1.2839e-02, -4.8771e-03, -4.2620e-03,\n",
              "         -3.0481e-02,  4.6085e-02, -2.8627e-03,  6.6756e-03, -2.6765e-03,\n",
              "         -4.1443e-02,  1.3336e-02, -1.0526e-02, -3.8494e-02,  1.2780e-02,\n",
              "         -3.5214e-02, -2.4758e-02,  7.5220e-03,  1.7225e-02, -1.6440e-02,\n",
              "         -3.6639e-03, -4.7462e-02,  5.3796e-04, -2.8419e-03,  4.5923e-03,\n",
              "         -3.0517e-02, -3.6832e-03,  1.8710e-02, -3.0486e-02, -2.4076e-02,\n",
              "         -2.7601e-02,  1.1921e-01,  1.2020e-01,  5.9805e-02, -6.9238e-03,\n",
              "         -1.3529e-01,  1.1234e-01,  8.3534e-02,  1.9974e-01,  5.3834e-02,\n",
              "         -6.6691e-02,  1.2676e-01,  2.4947e-01,  4.9879e-01, -1.6342e-01,\n",
              "          6.1663e-02, -4.8022e-02, -5.4069e-02,  4.7277e-02, -1.4724e-01,\n",
              "          8.4666e-02,  9.8618e-02,  7.9988e-02, -5.7652e-02,  6.3551e-03,\n",
              "          2.6916e-03,  9.2017e-02,  1.2511e-01,  2.5168e-01, -8.6152e-02,\n",
              "         -2.7570e-02, -6.1548e-02,  9.1371e-02,  8.0129e-02, -1.1662e-01,\n",
              "          1.5206e-01, -1.0687e-01, -1.0758e-01,  9.4138e-02,  1.0322e-01,\n",
              "         -1.5152e-01,  2.5472e-01,  7.0699e-02, -4.1571e-02,  2.7933e-02,\n",
              "         -1.9523e-01, -2.8319e-01,  5.9689e-02, -1.4707e-01, -3.5683e-02,\n",
              "         -5.4465e-02,  1.2570e-01, -1.2280e-01,  2.0263e-01, -1.0653e-02,\n",
              "          1.1058e-01, -9.1731e-04,  8.6605e-02, -1.7707e-02,  1.2616e-02,\n",
              "          1.8871e-01, -1.0594e-01, -3.7989e-03, -6.6359e-02, -5.9799e-02,\n",
              "          4.3201e-03, -2.3140e-02,  4.8008e-03,  1.4294e-02, -9.5453e-03,\n",
              "          5.8454e-03,  8.6512e-03,  2.1151e-02,  1.7098e-02, -1.4637e-03,\n",
              "          1.3778e-02, -1.2843e-02,  2.3742e-02, -1.3895e-02,  1.1327e-03,\n",
              "         -7.0846e-03, -7.6255e-03, -8.2264e-03, -1.5513e-02,  4.2724e-03,\n",
              "         -1.7624e-02, -3.0984e-03, -1.4400e-02,  2.3883e-02,  1.1556e-01,\n",
              "          4.4036e-02,  3.2821e-02,  8.6612e-04,  1.2383e-02, -6.6263e-03,\n",
              "         -2.7201e-03,  4.8125e-03, -2.8362e-03,  3.9830e-02,  5.2414e-02,\n",
              "         -4.6269e-03, -1.5858e-02,  2.1845e-02, -1.3767e-02, -1.0629e-02,\n",
              "          1.0347e-02, -3.4209e-02,  1.6939e-02,  1.8120e-02,  3.0650e-03,\n",
              "         -2.5109e-03,  1.3500e-02, -3.6440e-02, -9.2135e-03,  9.2194e-03,\n",
              "         -3.6276e-02, -1.1555e-02, -1.9569e-02, -1.5417e-02, -2.0485e-02,\n",
              "          2.9770e-03, -6.8246e-03, -6.5039e-03, -1.2597e-02, -1.1409e-02,\n",
              "          1.7139e-02,  4.6424e-03, -5.1774e-02, -1.1679e-02,  5.2761e-03,\n",
              "         -1.3664e-02, -1.4001e-02,  2.0379e-03,  1.2753e-02, -8.1607e-03,\n",
              "         -1.0849e-02, -1.0683e-03, -2.4489e-03,  2.0192e-02,  1.5756e-02,\n",
              "         -6.4964e-03, -4.5603e-02, -2.5999e-02, -1.4307e-02, -7.4639e-03,\n",
              "          9.9480e-03,  1.6763e-02,  2.1737e-02,  4.8181e-02,  1.7739e-02,\n",
              "          1.1469e-02, -4.2359e-03, -1.6419e-02, -1.7318e-02,  1.1498e-03,\n",
              "          2.4485e-02, -3.0614e-03,  1.9017e-02, -1.6453e-02, -1.3444e-02,\n",
              "          2.6748e-02, -6.4994e-03,  5.1485e-03,  1.4132e-02, -1.1573e-02,\n",
              "          1.2583e-02, -1.1401e-02, -2.0003e-02, -3.8115e-03,  7.3728e-03,\n",
              "          1.5500e-02,  2.0623e-02,  3.1582e-03, -1.2794e-02,  4.5499e-03,\n",
              "         -3.3994e-04, -2.3003e-02,  1.2225e-02, -2.7949e-02, -9.6121e-03,\n",
              "         -3.5844e-02, -4.2373e-03,  5.3473e-03,  1.4432e-02, -1.2745e-02,\n",
              "          7.1483e-03,  2.9170e-03,  6.2454e-03,  6.8991e-03,  1.5852e-02,\n",
              "          2.1877e-02, -1.7211e-02, -2.6093e-02]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## computeSize"
      ],
      "metadata": {
        "id": "4YPkuVIW4GNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "torch.save(obj=pipe.model.state_dict(), f=\"model.pt\")"
      ],
      "metadata": {
        "id": "r7_l0cJsmq4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Path(\"/content/model.pt\").stat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9K_sKm1n8b4",
        "outputId": "3863fd6d-0ec6-41b1-ebd0-0ee8e674745f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "os.stat_result(st_mode=33188, st_ino=4980924, st_dev=55, st_nlink=1, st_uid=0, st_gid=0, st_size=438459014, st_atime=1703875130, st_mtime=1703875132, st_ctime=1703875132)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path(\"/content/model.pt\").stat().st_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiGm63JJxVpt",
        "outputId": "18b01a9c-12d7-4612-bbf9-d86edc8caa48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "438459014"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def computeSize(self):\n",
        "    \"\"\"Override the PerformanceBenchmark.compute_size() method\"\"\"\n",
        "    state_dict=self.pipeline.model.state_dict()\n",
        "    tmp_path=Path(\"model.pt\")\n",
        "    torch.save(obj=state_dict, f=tmp_path)\n",
        "    # Calculate size in megabytes(MB)\n",
        "    size_mb=Path(tmp_path).stat().st_size / (1024*1024)\n",
        "    # Delete temporary file\n",
        "    tmp_path.unlink()\n",
        "    print(f\"Model Size ---> {size_mb:.2f} mb\")\n",
        "    return {\"size_mb\":size_mb}\n",
        "PerformanceBenchmark.computeSize=computeSize"
      ],
      "metadata": {
        "id": "BCS5sOUJxqu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple way to measure the execution time of a code snippet is to use the `perf_counter()` function from Python's `time` module. This function has a **better time resolution** than the `time.time()` function and is well suited for getting precise results."
      ],
      "metadata": {
        "id": "AiQq4Qee2iKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## timePipeline\n",
        "> Compute the average Latency from feeding input to getting output."
      ],
      "metadata": {
        "id": "00jwOPhx4UOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter\n",
        "\n",
        "for _ in range(3):\n",
        "    start_time=perf_counter()\n",
        "    _=pipe(data[\"test\"][0][\"text\"])\n",
        "    latency=perf_counter() - start_time\n",
        "    print(f\"Latency: {1000*latency:.3f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faMhMbeS21r1",
        "outputId": "9e7a37cc-126e-4dc0-d6b4-4c5da81ebd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency: 100.242 ms\n",
            "Latency: 102.908 ms\n",
            "Latency: 94.523 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def timePipeline(self, query=\"What is the pin number for my account?\"):\n",
        "    \"\"\"Override the PerformanceBenchmark.time_pipeline() method\"\"\"\n",
        "    latencies:[float]=[]\n",
        "    # Warmup the CPU before performing actual timed run\n",
        "    for _ in range(10):\n",
        "        _=self.pipeline(query)\n",
        "    # Timed Run\n",
        "    for _ in range(100):\n",
        "        start_time=perf_counter()\n",
        "        _=self.pipeline(query)\n",
        "        latency=perf_counter() - start_time\n",
        "        latencies.append(latency)\n",
        "    # Compute run statistics\n",
        "    avg_time_in_ms=1000 * np.mean(latencies)\n",
        "    std_time_in_ms=1000 * np.std(latencies)\n",
        "    print(f\"Latency: {avg_time_in_ms:.2f} ms +\\- {std_time_in_ms:.2f} ms\")\n",
        "    return {\n",
        "        \"avg_time_in_ms\":avg_time_in_ms,\n",
        "        \"std_time_in_ms\":std_time_in_ms\n",
        "    }\n",
        "\n",
        "PerformanceBenchmark.timePipeline=timePipeline"
      ],
      "metadata": {
        "id": "gVApFcxm249t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the `latency` will depend on the query length, and a good practice is to **benchmark your models with queries that they're likely to encounter in production environments**."
      ],
      "metadata": {
        "id": "4g6Puzoo7qcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Benchmarking\n",
        "> For the **baseline model**, we just need to pass the pipeline and the dataset we wish to perform the benchmark on."
      ],
      "metadata": {
        "id": "uOD79gr28HZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance_benchmark=PerformanceBenchmark(pipeline=pipe, dataset=data)\n",
        "performance_metrics=performance_benchmark.runBenchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG7RmRiu3RRX",
        "outputId": "61f56f7a-77b3-4537-a4a2-28de79278a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size ---> 418.15 mb\n",
            "Latency: 86.24 ms +\\- 10.03 ms\n",
            "Accuracy on test set ---> 0.8673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Distillation\n",
        "> Making Models Smaller via Knowledge Distillation"
      ],
      "metadata": {
        "id": "QcqjQPPjfj65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Knowledge distillation**: A smaller model (student) to mimic the behavior of a slower, larger, but better-performing model (teacher).\n",
        "\n",
        "* **Soft probabilities**: The teacher's confidence scores for each possible output, which give extra information to the student.\n",
        "\n",
        "* **Dark knowledge**: The teacher's insights that are not captured by the labels alone, such as the similarity of different outputs.\n",
        "\n",
        "* **History**: First used for ensemble models in 2006, then extended to deep neural networks in 2015.\n",
        "\n",
        "* **Applications**: Used to `compress large pretrained language models` for practical use."
      ],
      "metadata": {
        "id": "y3m-rT4YgId3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Knowledge Distillation Trainer"
      ],
      "metadata": {
        "id": "Hz9SuNvl_1br"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement **knowledge distillation** we need to add a few things to the `Trainer` base class:\n",
        "\n",
        "* The new hyperparameters `Œ±` and `T`, which control the relative weight of the `distillation loss` and how much the probability distribution of the labels should be smoothed.\n",
        "\n",
        "* The fine-tuned teacher model, which in our case is BERT-base.\n",
        "\n",
        "* A new loss function that combines the cross-entropy loss with the knowledge distillation loss.\n",
        "\n",
        "Adding the new hyperparameters is quite simple, since we just need to subclass `TrainingArguments` and include them as new attributes:"
      ],
      "metadata": {
        "id": "HGKBdrRlBYxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.alpha=alpha\n",
        "        self.temperature=temperature\n"
      ],
      "metadata": {
        "id": "9NWbcQPP85Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the trainer itself, we need a new loss function. The way to implement this is by subclassing `Trainer` and overriding the `compute_loss()` method to include the `knowledge distillation loss` term $L_{KD}$.\n",
        "\n",
        "* **Cross Entropy Loss:** measures how well the `student model predicts` the correct labels.\n",
        "\n",
        "* **Knowledge Distillation Loss:** measures how well the `student model mimics` the teacher model's output.\n"
      ],
      "metadata": {
        "id": "-uq1MqIfCkKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "\n",
        "class DistillationTrainer(Trainer):\n",
        "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.teacher_model=teacher_model\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        student_outputs=model(**inputs)\n",
        "        # Extract Cross Entropy Loss and Logits from Student\n",
        "        cross_entropy_loss=student_outputs.loss\n",
        "        student_logits=student_outputs.logits\n",
        "\n",
        "        # Extract logits from Teacher\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs=self.teacher_model(**inputs)\n",
        "            teacher_logits=teacher_outputs.logits\n",
        "        # Soften Probabilities and Compute Distillation Loss\n",
        "        loss_function=nn.KLDivLoss(reduction=\"batchmean\")\n",
        "        # Temperature\n",
        "        T=self.args.temperature\n",
        "        knowledge_distillation_loss=T ** 2 * loss_function(\n",
        "            F.log_softmax(student_logits/T, dim=-1),\n",
        "            F.softmax(teacher_logits/T, dim=-1)\n",
        "        )\n",
        "\n",
        "        # Return weighted student loss\n",
        "        loss=self.args.alpha * cross_entropy_loss + (1. - self.args.alpha) * knowledge_distillation_loss\n",
        "        return (loss, student_outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "pMYYw2UyAFfy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2-Yzz4vDrMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing a good student initialization"
      ],
      "metadata": {
        "id": "7l89EXCwR0JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WG8IbZqKSFmS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "podUCQMGR6Gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}