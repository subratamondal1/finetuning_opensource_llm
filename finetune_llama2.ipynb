{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "bxGr9-_hqhsL",
        "-9ak11lRsit_",
        "ye81ySkotWqS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71b457e297cc4f25a505270527d0ca3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bf217c2aa34414aba43aef28cdda79f",
              "IPY_MODEL_40103a6d1e494d85b7ebe4aa31d90516",
              "IPY_MODEL_e4604e1c8cb947f7b5351211b5b8c8b8",
              "IPY_MODEL_7b3eb653e76f4775b44240e092f420da"
            ],
            "layout": "IPY_MODEL_1451a39306304a55aadf46f05de2bd72"
          }
        },
        "23e2d910643b4e19b89a5f119d723cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ff9da7d22444ebad5950b4a969007e",
            "placeholder": "​",
            "style": "IPY_MODEL_21ef2d191d904cd0897009c08b18f83b",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "0a4ee5d5c9b844289989b3e139de2876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bf347ba91f8e495a9bbeed0f21d9c5e0",
            "placeholder": "​",
            "style": "IPY_MODEL_cf6dfdf2dc41410ba120cf1755672d23",
            "value": ""
          }
        },
        "2bcdbb85912140aa8868a433b1514cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b5e1ba4ad848429a9b6e91a700972b1b",
            "style": "IPY_MODEL_8f4f1de9e1e640a0bf06ed27be5cb520",
            "value": true
          }
        },
        "7a5c6003926a448fbe4260be7b46d0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_12a2d6e7c793430dba6641c525427cbe",
            "style": "IPY_MODEL_a821637299ea41c8a2f4dfaf31e2d775",
            "tooltip": ""
          }
        },
        "64feca7c97944915a871e74fdaff6e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333667bb5b1d440b9bdb19880c39ee75",
            "placeholder": "​",
            "style": "IPY_MODEL_fac98f06a24b40999aefd5a8a83b6cd2",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "1451a39306304a55aadf46f05de2bd72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "04ff9da7d22444ebad5950b4a969007e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ef2d191d904cd0897009c08b18f83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf347ba91f8e495a9bbeed0f21d9c5e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf6dfdf2dc41410ba120cf1755672d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5e1ba4ad848429a9b6e91a700972b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4f1de9e1e640a0bf06ed27be5cb520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a2d6e7c793430dba6641c525427cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a821637299ea41c8a2f4dfaf31e2d775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "333667bb5b1d440b9bdb19880c39ee75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac98f06a24b40999aefd5a8a83b6cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1c2363cc11f46e4a0db7bc4fcc95d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f6af4a29494a48a2d4f278aee1a640",
            "placeholder": "​",
            "style": "IPY_MODEL_75001d2d78734f9592412c5635d2746d",
            "value": "Connecting..."
          }
        },
        "44f6af4a29494a48a2d4f278aee1a640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75001d2d78734f9592412c5635d2746d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bf217c2aa34414aba43aef28cdda79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc5f3fc1e2294ae089fbfe484366ea23",
            "placeholder": "​",
            "style": "IPY_MODEL_917f07f4d716468fa233f0d866733024",
            "value": "Token is valid (permission: write)."
          }
        },
        "40103a6d1e494d85b7ebe4aa31d90516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146542405a9b48198fc3e0dd0b9b19c9",
            "placeholder": "​",
            "style": "IPY_MODEL_5a70c8963ba8407ba52fa6e2b7abfa9e",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "e4604e1c8cb947f7b5351211b5b8c8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5007b6d4ce84f199f227ebbfc43b6ea",
            "placeholder": "​",
            "style": "IPY_MODEL_b607254bc52a41ff930be36e27ee855a",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "7b3eb653e76f4775b44240e092f420da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aac53a3571e480fb4e7b3d49182be13",
            "placeholder": "​",
            "style": "IPY_MODEL_7408046da5164edf971f73bb1fdfa36f",
            "value": "Login successful"
          }
        },
        "fc5f3fc1e2294ae089fbfe484366ea23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917f07f4d716468fa233f0d866733024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "146542405a9b48198fc3e0dd0b9b19c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a70c8963ba8407ba52fa6e2b7abfa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5007b6d4ce84f199f227ebbfc43b6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b607254bc52a41ff930be36e27ee855a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aac53a3571e480fb4e7b3d49182be13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7408046da5164edf971f73bb1fdfa36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2905510,
          "sourceType": "datasetVersion",
          "datasetId": 1780768
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "bxGr9-_hqhsL",
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install transformers==4.31 #temporary fix required owing to breaking changes on Aug 9th 2023\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "c89kbCCoqj4r",
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Login"
      ],
      "metadata": {
        "id": "-9ak11lRsit_",
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "5QpD9WOFrNvJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "71b457e297cc4f25a505270527d0ca3c",
            "23e2d910643b4e19b89a5f119d723cd7",
            "0a4ee5d5c9b844289989b3e139de2876",
            "2bcdbb85912140aa8868a433b1514cfb",
            "7a5c6003926a448fbe4260be7b46d0a3",
            "64feca7c97944915a871e74fdaff6e53",
            "1451a39306304a55aadf46f05de2bd72",
            "04ff9da7d22444ebad5950b4a969007e",
            "21ef2d191d904cd0897009c08b18f83b",
            "bf347ba91f8e495a9bbeed0f21d9c5e0",
            "cf6dfdf2dc41410ba120cf1755672d23",
            "b5e1ba4ad848429a9b6e91a700972b1b",
            "8f4f1de9e1e640a0bf06ed27be5cb520",
            "12a2d6e7c793430dba6641c525427cbe",
            "a821637299ea41c8a2f4dfaf31e2d775",
            "333667bb5b1d440b9bdb19880c39ee75",
            "fac98f06a24b40999aefd5a8a83b6cd2",
            "c1c2363cc11f46e4a0db7bc4fcc95d33",
            "44f6af4a29494a48a2d4f278aee1a640",
            "75001d2d78734f9592412c5635d2746d",
            "3bf217c2aa34414aba43aef28cdda79f",
            "40103a6d1e494d85b7ebe4aa31d90516",
            "e4604e1c8cb947f7b5351211b5b8c8b8",
            "7b3eb653e76f4775b44240e092f420da",
            "fc5f3fc1e2294ae089fbfe484366ea23",
            "917f07f4d716468fa233f0d866733024",
            "146542405a9b48198fc3e0dd0b9b19c9",
            "5a70c8963ba8407ba52fa6e2b7abfa9e",
            "c5007b6d4ce84f199f227ebbfc43b6ea",
            "b607254bc52a41ff930be36e27ee855a",
            "4aac53a3571e480fb4e7b3d49182be13",
            "7408046da5164edf971f73bb1fdfa36f",
            "8b3ebcc21a484d2190f55c373085dd29"
          ]
        },
        "outputId": "d54667b0-6a39-47f3-8d8e-0f220205039c",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:22.727604Z",
          "iopub.execute_input": "2024-01-02T21:17:22.727951Z",
          "iopub.status.idle": "2024-01-02T21:17:23.209127Z",
          "shell.execute_reply.started": "2024-01-02T21:17:22.727901Z",
          "shell.execute_reply": "2024-01-02T21:17:23.208152Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b3ebcc21a484d2190f55c373085dd29"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "dETLOL8UseIn",
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Weights"
      ],
      "metadata": {
        "id": "fEkKzx64DBul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llama2 family is a group of large language models (LLMs) that can generate natural language texts for various tasks, such as writing, chatting, coding, etc. Llama2 consists of three models with different numbers of parameters:\n",
        "\n",
        "* **7b model** has **7 billion** parameters and needs **28 GB** of memory\n",
        "* **13b model** has **13 billion** parameters and needs **52 GB** of memory\n",
        "* **70b model** has **70 billion** parameters and needs **280 GB** of memory\n",
        "\n",
        "If each `weight` is represented by `32-bits`, then\n",
        "* `1 byte = 8 bits`\n",
        "* 70b model\n",
        "* 70b * 32bits / (8 bits per byte) = 70b * 4 = `280 GB` of weights.\n",
        "\n",
        "\n",
        "Similarly, for 7b model\n",
        "* 1 byte = 8 bits\n",
        "* 7b model\n",
        "* 7b * 32bits / (8 bits per byte) = 7b * 4 = `28 GB` of weights.\n",
        "\n",
        "Most powerful computers\n",
        "* Nvidia A100 - 40GB, 80GB\n",
        "\n",
        "The memory requirements of these models are very high, and they **cannot be loaded on most computers** or platforms. For example, the most powerful computers, such as Nvidia A100, have only 40 GB or 80 GB of memory. Google Colab, a free platform that provides GPUs for training models, has only 15 GB of memory. Therefore, to solve this problem, we use **Quantization**.\n",
        "\n"
      ],
      "metadata": {
        "id": "SK5mGRVuDF40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "GnLpgub0MtQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantization** is a technique that reduces the size of the model by using fewer bits to represent a weight. A weight is a numerical value that determines how the model processes the input and produces the output. The more bits are used to represent a weight, the more precise and accurate the weight is, but also the more memory and computation it requires.\n",
        "\n",
        "Quantization has the following benefits and drawbacks:\n",
        "\n",
        "* **Benefits:**\n",
        "    * Reduces the memory usage of the model by a factor of the bit reduction. For example, reducing from 32 bits to 4 bits reduces the memory usage by 8 times.\n",
        "\n",
        "    * Improves the speed and efficiency of the model by using less resources and power.\n",
        "\n",
        "    * Enables the model to run on platforms or devices that have limited memory or computation capabilities, such as Google Colab, microcontrollers, or embedded systems.\n",
        "\n",
        "* **Drawbacks:**\n",
        "    * Introduces quantization error, which is the difference between the original weight and the quantized weight. This error can affect the quality and accuracy of the model, especially for sensitive or complex tasks.\n",
        "\n",
        "    * Requires careful tuning and calibration of the quantization parameters, such as the scale and zero-point, to minimize the quantization error and preserve the model performance.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Let's see an example of how quantization works. Suppose we have a model with 7 billion weights, and each weight is represented by 32 bits. The memory usage of this model is:\n",
        "\n",
        "- 7b * 32 bits / (8 bits per byte) = 28 GB\n",
        "\n",
        "This model is too large to fit in Google Colab, which has only 15 GB of memory. To reduce the size of the model, we can quantize the weights from 32 bits to 4 bits. The memory usage of the quantized model is:\n",
        "\n",
        "- 7b * 4 bits / (8 bits per byte) = 3.5 GB\n",
        "\n",
        "This model is much smaller and can be easily stored in Google Colab for further manipulation or fine-tuning. Here is a table that compares the memory usage of different models before and after quantization:\n",
        "\n",
        "| Model | Number of weights | Bits per weight | Memory usage |\n",
        "|-------|-------------------|-----------------|--------------|\n",
        "| Original | 7 billion | 32 | 28 GB |\n",
        "| Quantized | 7 billion | 4 | 3.5 GB |\n",
        "| Reduced | 1 billion | 32 | 4 GB |\n",
        "\n",
        "As you can see, quantizing the weights from 32 bits to 4 bits reduces the memory usage by 8 times, from 28 GB to 3.5 GB. This is equivalent to reducing the number of weights by 8 times, from 7 billion to 1 billion, while keeping the same bit size of 32."
      ],
      "metadata": {
        "id": "fKvCOYIkMvQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantization Types**\n",
        "\n",
        "There are different types of quantization techniques that can be applied to models, depending on the stage and the method of quantization.\n",
        "\n",
        "* **Post-training quantization:** This type of quantization is `applied after the model is trained, without retraining or fine-tuning the model`. It is the simplest and fastest way to quantize a model, but it may result in more accuracy loss than other types. There are different methods of post-training quantization, such as **static quantization**, **dynamic quantization**, and **quantization-aware pruning**.\n",
        "\n",
        "* **Quantization-aware training:** This type of quantization is applied `during the model training process`, by simulating the effects of quantization on the model weights and activations. It is more complex and time-consuming than post-training quantization, but it can achieve higher accuracy and lower quantization error than post-training quantization. There are different methods of quantization-aware training, such as **fake quantization**, **quantization noise injection**, and **stochastic rounding**.\n",
        "\n",
        "* **Mixed-precision quantization:** This type of quantization is applied by using `different precisions` for different parts of the model, such as weights, activations, gradients, and accumulators. It is a flexible and efficient way to quantize."
      ],
      "metadata": {
        "id": "2brq7vJOY-qV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Efficient Fine Tuning (PEFT)\n",
        "> PEFT means \"we only train some weights\"."
      ],
      "metadata": {
        "id": "F36KG1lPRT6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LoRA** and **QLoRA** are powerful tools for **adapting pre-trained language models to specific tasks** while **optimizing memory usage**.\n",
        "\n",
        "**LoRA** - **L**ow **R**ank **A**daptatiion means instead of training all the 7-Billion Parameters, we train(update) only the most important ones.\n",
        "\n",
        "**QLoRA** - Quantized LoRA means Parameter Efficient Fine Tuning but with Quantized Weights of 4-bits (here).\n",
        "\n",
        "**BitsAndBytes** - Hugging Face developed Quantization library that supports LoRA.\n"
      ],
      "metadata": {
        "id": "-qaHIGdIRYA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"Trelis/Llama-2-7b-chat-hf-sharded-bf16\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"
      ],
      "metadata": {
        "id": "ODMZ9V_NrdUr",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.210570Z",
          "iopub.execute_input": "2024-01-02T21:17:23.210855Z",
          "iopub.status.idle": "2024-01-02T21:17:23.215176Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.210829Z",
          "shell.execute_reply": "2024-01-02T21:17:23.214126Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **iamsubrata/Llama-2-7b-chat-hf-sharded-bf16-fine-tuned**: FineTuned **Llama-2-7b-chat-hf-sharded-bf16** (optimized for dialogue use cases)\n",
        "on `Enhglish Quotes Dataset`.\n",
        "\n",
        "* **BitsAndBytesConfig** is used to configure for **model quantization**, which is a technique to reduce the memory and computation requirements of LLM by using lower-precision data types.\n",
        "    * **load_in_4bit**: Load the model weights in 4-bit precision, which reduces the model size by **75%** compared to **16-bit precision**.\n",
        "    \n",
        "    * **bnb_4bit_use_double_quant**: Leverages **double quantization**, which is a method to further compress the model by using `two quantization levels`: one for the **most frequent values** and one **for the rest**.\n",
        "    \n",
        "    * **bnb_4bit_quant_type**: Quantization type: **nf4**, which stands for **nibble float 4**, a custom data type that uses 4 bits to\n",
        "    represent floating-point numbers.\n",
        "    \n",
        "    - **bnb_4bit_compute_dtype**: This specifies the data type to use for the model computation, **torch.bfloat16**, which is a `16-bit floating-point` format that preserves more dynamic range than 16-bit integer formats.\n",
        "\n",
        "* A **causal language model** is a type of generative model that **predicts the next token in a sequence given the previous tokens**."
      ],
      "metadata": {
        "editable": false,
        "id": "3Ghxq4wNCzfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Setup (PEFT)"
      ],
      "metadata": {
        "id": "P99wYPRpss_4",
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "dwKtuYKKrlwM",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.217401Z",
          "iopub.execute_input": "2024-01-02T21:17:23.217659Z",
          "iopub.status.idle": "2024-01-02T21:17:23.226825Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.217636Z",
          "shell.execute_reply": "2024-01-02T21:17:23.225722Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "M4cKOHgKs1Pb",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.228196Z",
          "iopub.execute_input": "2024-01-02T21:17:23.228666Z",
          "iopub.status.idle": "2024-01-02T21:17:23.238504Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.228631Z",
          "shell.execute_reply": "2024-01-02T21:17:23.237580Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    # target_modules=[\"query_key_value\"],\n",
        "    target_modules=[\"self_attn.q_proj\", \"self_attn.k_proj\", \"self_attn.v_proj\", \"self_attn.o_proj\"], #specific to Llama models.\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "0xd9wwB-s1rO",
        "execution": {
          "iopub.status.busy": "2024-01-03T04:43:31.248402Z",
          "iopub.execute_input": "2024-01-03T04:43:31.248848Z",
          "iopub.status.idle": "2024-01-03T04:43:31.254484Z",
          "shell.execute_reply.started": "2024-01-03T04:43:31.248803Z",
          "shell.execute_reply": "2024-01-03T04:43:31.253370Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup"
      ],
      "metadata": {
        "id": "4BgmGP3fs7Xx",
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **english_quotes dataset** is a collection of quotes from **goodreads.com**, a website that allows users to rate and review books. The dataset contains **3,910 quotes**, each with the following attributes:\n",
        "\n",
        "* **quote:** The content of the quote in English\n",
        "* **author:** The name of the author who said or wrote the quote\n",
        "* **tags:** A list of keywords that describe the theme or topic of the quote\n",
        "\n",
        "The dataset can be used for multi-label text classification and text generation tasks. For example, you can train a model to predict the tags of a given quote, or to generate a quote based on a given tag or author."
      ],
      "metadata": {
        "id": "VHhRtGn0Z4yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "data_path=\"Abirate/english_quotes\"\n",
        "data = load_dataset(data_path)\n",
        "data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)"
      ],
      "metadata": {
        "id": "_Wcoqil1s4i-",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.253622Z",
          "iopub.status.idle": "2024-01-02T21:17:23.254024Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.253807Z",
          "shell.execute_reply": "2024-01-02T21:17:23.253834Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment if the above block doesn't work, and make sure to add the dataset from kaggle\n",
        "# from datasets import load_dataset\n",
        "# data_path=\"/kaggle/input/english-quotes/quotes.jsonl\"\n",
        "# data = load_dataset(\"json\",data_files={\n",
        "#     \"train\":data_path\n",
        "# })\n",
        "# data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)"
      ],
      "metadata": {
        "editable": false,
        "id": "xo-mZSywCzfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "7MVitcRWtF-U",
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "# needed for Llama tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token # </s>\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data[\"train\"],\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=2,\n",
        "        max_steps=10,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\"\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings.\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "4i5kg2gTtGzL",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.255297Z",
          "iopub.status.idle": "2024-01-02T21:17:23.255637Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.255468Z",
          "shell.execute_reply": "2024-01-02T21:17:23.255484Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "pFggC3PAB83q",
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "log_dir = \"/kaggle/working/outputs/runs\" # make sure this path is correct\n",
        "notebook.start(\"--logdir {} --port 4000\".format(log_dir))"
      ],
      "metadata": {
        "id": "uBZfMl7eCFVc",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.324428Z",
          "iopub.status.idle": "2024-01-02T21:17:23.324861Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.324665Z",
          "shell.execute_reply": "2024-01-02T21:17:23.324682Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "uDkMJCoktKjT",
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **TextStreamer** class enables streaming of the generated text, which means that the text is printed to the standard output as soon as each token is generated, instead of waiting for the whole response to be generated."
      ],
      "metadata": {
        "editable": false,
        "id": "qZr2wIBiCzfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "6QZ2Vb3WtLez",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.328016Z",
          "iopub.status.idle": "2024-01-02T21:17:23.328409Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.328227Z",
          "shell.execute_reply": "2024-01-02T21:17:23.328244Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a stream *without* function calling capabilities\n",
        "def stream(user_prompt,model):\n",
        "    runtimeFlag = \"cuda:0\"\n",
        "    system_prompt = 'You are a helpful assistant that provides accurate and concise responses'\n",
        "\n",
        "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "    prompt = f\"{B_INST} {B_SYS}{system_prompt.strip()}{E_SYS}{user_prompt.strip()} {E_INST}\\n\\n\"\n",
        "\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(runtimeFlag)\n",
        "\n",
        "    streamer = TextStreamer(tokenizer)\n",
        "\n",
        "    # Despite returning the usual output, the streamer will also print the generated text to stdout.\n",
        "    _ = model.generate(**inputs, streamer=streamer, max_new_tokens=500)"
      ],
      "metadata": {
        "id": "mKUihTHNtP6O",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.329781Z",
          "iopub.status.idle": "2024-01-02T21:17:23.330136Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.329966Z",
          "shell.execute_reply": "2024-01-02T21:17:23.329983Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream('Provide a very brief comparison of salsa and bachata.',model)"
      ],
      "metadata": {
        "id": "5G-WvZ9ftSOX",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.331217Z",
          "iopub.status.idle": "2024-01-02T21:17:23.331556Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.331388Z",
          "shell.execute_reply": "2024-01-02T21:17:23.331404Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Push Fine Tuned Model to Hub"
      ],
      "metadata": {
        "id": "ye81ySkotWqS",
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment if you want to push it in your hub\n",
        "# # Extract the last portion of the base_model\n",
        "# base_model_name = model_id.split(\"/\")[-1]\n",
        "\n",
        "# # Change the \"iamsubrata\" part with your Hugging Face Repo Name\n",
        "# adapter_model = f\"iamsubrata/{base_model_name}-fine-tuned-adapters\"\n",
        "# new_model = f\"iamsubrata/{base_model_name}-fine-tuned\""
      ],
      "metadata": {
        "id": "SGgYSAs7taf1",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.334608Z",
          "iopub.status.idle": "2024-01-02T21:17:23.334937Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.334761Z",
          "shell.execute_reply": "2024-01-02T21:17:23.334776Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Note** Adapter Model doesn't have `config.json` file in it, to get it we have to merge the Adapter Model with the Pretrained Model. And without `config.json` file will not be able to load it from the hub, it will give `config.json` **file not found error**."
      ],
      "metadata": {
        "editable": false,
        "id": "E6sMUIdoCzfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the adapter model (doesn't have config.json)\n",
        "# model.save_pretrained(adapter_model, push_to_hub=True, use_auth_token=True)\n",
        "\n",
        "# # Push the adapter model to the hub\n",
        "# model.push_to_hub(adapter_model, use_auth_token=True)"
      ],
      "metadata": {
        "id": "hu4T6vhyt2aP",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.335811Z",
          "iopub.status.idle": "2024-01-02T21:17:23.336159Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.335988Z",
          "shell.execute_reply": "2024-01-02T21:17:23.336005Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Reload the base model without quantization**, it might(certainly) crash the free tier version of your notebook as it is loading the whole model."
      ],
      "metadata": {
        "editable": false,
        "id": "WSfXUiwXCzfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the base model without quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='cpu', trust_remote_code=True, torch_dtype=torch.float16, cache_dir=\"cache\")"
      ],
      "metadata": {
        "id": "fPkR9KVnvZh8",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.337135Z",
          "iopub.status.idle": "2024-01-02T21:17:23.337477Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.337292Z",
          "shell.execute_reply": "2024-01-02T21:17:23.337307Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# load perf model with new adapters\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    adapter_model,\n",
        ")"
      ],
      "metadata": {
        "id": "5YCyh99wIeQj",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.339224Z",
          "iopub.status.idle": "2024-01-02T21:17:23.339730Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.339508Z",
          "shell.execute_reply": "2024-01-02T21:17:23.339530Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.merge_and_unload() # merge adapters with the base model."
      ],
      "metadata": {
        "id": "K48eL4ZWIkY4",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.341145Z",
          "iopub.status.idle": "2024-01-02T21:17:23.341542Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.341348Z",
          "shell.execute_reply": "2024-01-02T21:17:23.341367Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(new_model, use_auth_token=True, max_shard_size=\"5GB\")"
      ],
      "metadata": {
        "id": "LByx_50fInLa",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.343080Z",
          "iopub.status.idle": "2024-01-02T21:17:23.343448Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.343261Z",
          "shell.execute_reply": "2024-01-02T21:17:23.343278Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push the tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "tokenizer.push_to_hub(new_model, use_auth_token=True)"
      ],
      "metadata": {
        "id": "Ufrr1oAuIsRH",
        "execution": {
          "iopub.status.busy": "2024-01-02T21:17:23.344476Z",
          "iopub.status.idle": "2024-01-02T21:17:23.344820Z",
          "shell.execute_reply.started": "2024-01-02T21:17:23.344646Z",
          "shell.execute_reply": "2024-01-02T21:17:23.344662Z"
        },
        "editable": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Now, you can use the [inference notebook]() to use it for inference or you can use the `pipeline` from `transformers`.**"
      ],
      "metadata": {
        "editable": false,
        "id": "NAmI_ZksCzfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "editable": false,
        "id": "c2aYE4ymCzfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "finetuned_model_checkpoint = \"iamsubrata/Llama-2-7b-chat-hf-sharded-bf16-fine-tuned\"\n",
        "\n",
        "bitsandbytes_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(finetuned_model_checkpoint, quantization_config=bitsandbytes_config, device_map={\"\":0})"
      ],
      "metadata": {
        "editable": false,
        "id": "WfP-7EbgCzfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "# Define a stream *without* function calling capabilities\n",
        "def stream(user_prompt,model):\n",
        "    runtimeFlag = \"cuda:0\"\n",
        "    system_prompt = 'You are a helpful assistant that provides accurate and concise responses'\n",
        "\n",
        "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "    prompt = f\"{B_INST} {B_SYS}{system_prompt.strip()}{E_SYS}{user_prompt.strip()} {E_INST}\\n\\n\"\n",
        "\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(runtimeFlag)\n",
        "\n",
        "    streamer = TextStreamer(tokenizer)\n",
        "\n",
        "    # Despite returning the usual output, the streamer will also print the generated text to stdout.\n",
        "    _ = model.generate(**inputs, streamer=streamer, max_new_tokens=500)"
      ],
      "metadata": {
        "editable": false,
        "id": "ajXqxucfCzfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream('Can you tell me quotes related to universe?.',model)"
      ],
      "metadata": {
        "editable": false,
        "id": "4fMFqY16CzfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Fine Tuning\n",
        "* Prompt Masking\n",
        "* End of sequence token"
      ],
      "metadata": {
        "id": "a_w97aHPUjBP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gVHkwvwaUmUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}